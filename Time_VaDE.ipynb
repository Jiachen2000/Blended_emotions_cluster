{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import itertools\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels[:,0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(Y_pred, Y):\n",
    "    assert Y_pred.size == Y.size\n",
    "    D = max(Y_pred.max(), Y.max())+1\n",
    "    w = np.zeros((D,D), dtype=np.int64)\n",
    "    for i in range(Y_pred.size):\n",
    "        w[Y_pred[i], Y[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    return sum([w[i, j] for i, j in zip(row_ind, col_ind)]) * 1.0 / Y_pred.size, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, input_channels, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(128, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_sigma = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.contiguous().view(-1, x.size(-1)) # flatten\n",
    "        x = self.fc1(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_sigma(x)\n",
    "\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_channels, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(128, output_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc2(z)\n",
    "        z = self.fc3(z)\n",
    "        z = z.contiguous().view(-1, 64, z.size(1)) # reshape\n",
    "        z = self.decoder(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaDE(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(VaDE, self).__init__()\n",
    "        self.encoder = Encoder(10, 299, 25)\n",
    "        self.decoder = Decoder(10, 299, 25)\n",
    "\n",
    "        self.pi = nn.Parameter(torch.FloatTensor(args.nClusters,).fill_(1)/args.nClusters, requires_grad=True) # inital cluster probabilities\n",
    "        self.mu_c = nn.Parameter(torch.FloatTensor(args.nClusters, args.latent_dim).fill_(0), requires_grad=True) # inital cluster means\n",
    "        self.logvar_c = nn.Parameter(torch.FloatTensor(args.nClusters, args.latent_dim).fill_(0), requires_grad=True) # inital cluster variances\n",
    "\n",
    "        self.args = args\n",
    "\n",
    "    def pre_train(self, dataloader, pre_epoch=10):\n",
    "        \n",
    "        if not os.path.exists(\"./pretrain_model.pk\"):\n",
    "            Loss = nn.MSELoss()\n",
    "            optimizer = Adam(itertools.chain(self.encoder.parameters(), self.decoder.parameters()), lr=1e-3)\n",
    "\n",
    "            print(\"Pre-training...\")\n",
    "            epoch_bar = tqdm(range(pre_epoch))\n",
    "            for _ in epoch_bar:\n",
    "                L = 0\n",
    "                for x, y in dataloader:\n",
    "                    if self.args.cuda:\n",
    "                        x = x.cuda()\n",
    "                    \n",
    "                    z, _ = self.encoder(x)\n",
    "                    x_recon = self.decoder(z)\n",
    "                    loss = Loss(x_recon, x)\n",
    "                    L += loss.detach().cpu().numpy()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                epoch_bar.write('L2={:.4f}'.format(L/len(dataloader)))\n",
    "\n",
    "            self.encoder.fc_sigma.load_state_dict(self.encoder.fc_mu.state_dict())\n",
    "\n",
    "            Z = []\n",
    "            Y = []\n",
    "            with torch.no_grad():\n",
    "                for x, y in dataloader:\n",
    "                    if self.args.cuda:\n",
    "                        x = x.cuda()\n",
    "                    \n",
    "                    z_mu, z_logvar = self.encoder(x) # dim -> (batch_size*64, latent_dim)\n",
    "                    assert F.mse_loss(z_mu, z_logvar) == 0\n",
    "                    y = y.repeat_interleave(64) # dim -> (batch_size*64,)\n",
    "                    Z.append(z_mu)\n",
    "                    Y.append(y)\n",
    "\n",
    "            Z = torch.cat(Z, dim=0).cpu().numpy()\n",
    "            Y = torch.cat(Y, dim=0).cpu().numpy()\n",
    "\n",
    "            gmm = GaussianMixture(n_components=self.args.nClusters, covariance_type='diag')\n",
    "\n",
    "            pre = gmm.fit_predict(Z)\n",
    "            print('Acc={:.4f}%'.format(cluster_acc(pre, Y)[0] * 100))\n",
    "\n",
    "            self.pi.data = torch.from_numpy(gmm.weights_).cuda().float()\n",
    "            self.mu_c.data = torch.from_numpy(gmm.means_).cuda().float()\n",
    "            self.logvar_c.data = torch.log(torch.from_numpy(gmm.covariances_).cuda().float())\n",
    "\n",
    "            torch.save(self.state_dict(), './pretrain_model.pk')\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.load_state_dict(torch.load('./pretrain_model.pk'))\n",
    "\n",
    "    def predict(self, x):\n",
    "        z_mu, z_logvar = self.encoder(x)\n",
    "        z = torch.randn_like(z_mu) * torch.exp(z_logvar/2) + z_mu # reparameterization trick\n",
    "        pi = self.pi\n",
    "        mu_c = self.mu_c\n",
    "        logvar_c = self.logvar_c\n",
    "        yita_c = torch.exp( torch.log(pi.unsqueeze(0)) + self.gaussian_pdfs_log(z, mu_c, logvar_c) ) # p(c)*p(z|c)\n",
    "        \n",
    "        yita = yita_c.detach().cpu().numpy()\n",
    "        return np.argmax(yita, axis=1)\n",
    "    \n",
    "    def ELBO_loss(self, x, L=1):\n",
    "        det = 1e-10\n",
    "        L_rec = 0\n",
    "        z_mu, z_logvar = self.encoder(x)\n",
    "        for l in range(L):\n",
    "            z = torch.randn_like(z_mu) * torch.exp(z_logvar/2) + z_mu # reparameterization trick\n",
    "            x_pro = self.decoder(z)\n",
    "            L_rec += F.binary_cross_entropy(x_pro, x)\n",
    "\n",
    "        L_rec/=L\n",
    "        Loss = L_rec*x.size(1)\n",
    "\n",
    "        pi=self.pi\n",
    "        log_sigma2_c=self.logvar_c\n",
    "        mu_c=self.mu_c\n",
    "\n",
    "        z = torch.randn_like(z_mu) * torch.exp(z_logvar / 2) + z_mu\n",
    "        yita_c=torch.exp(torch.log(pi.unsqueeze(0))+self.gaussian_pdfs_log(z,mu_c,log_sigma2_c))+det\n",
    "\n",
    "        yita_c=yita_c/(yita_c.sum(1).view(-1,1))#batch_size*Clusters\n",
    "\n",
    "        Loss+=0.5*torch.mean(torch.sum(yita_c*torch.sum(log_sigma2_c.unsqueeze(0)+\n",
    "                                                torch.exp(z_logvar.unsqueeze(1)-log_sigma2_c.unsqueeze(0))+\n",
    "                                                (z_mu.unsqueeze(1)-mu_c.unsqueeze(0)).pow(2)/torch.exp(log_sigma2_c.unsqueeze(0)),2),1))\n",
    "\n",
    "        Loss-=torch.mean(torch.sum(yita_c*torch.log(pi.unsqueeze(0)/(yita_c)),1))+0.5*torch.mean(torch.sum(1+z_logvar,1))\n",
    "\n",
    "\n",
    "        return Loss\n",
    "\n",
    "\n",
    "    def gaussian_pdfs_log(self,x,mus,log_sigma2s):\n",
    "        G=[]\n",
    "        for c in range(self.args.nClusters):\n",
    "            G.append(self.gaussian_pdf_log(x,mus[c:c+1,:],log_sigma2s[c:c+1,:]).view(-1,1))\n",
    "        return torch.cat(G,1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def gaussian_pdf_log(x,mu,log_sigma2):\n",
    "        return -0.5*(torch.sum(np.log(np.pi*2)+log_sigma2+(x-mu).pow(2)/torch.exp(log_sigma2),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args setting\n",
    "class Args:\n",
    "    def __init__(self, nClusters=15, latent_dim=10, cuda=True):\n",
    "        self.nClusters = nClusters\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cuda = cuda\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = torch.load('data_100_mouth.pt')\n",
    "labels = torch.load('labels_100_mouth.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set\n",
    "dataset = CustomDataset(data, labels)\n",
    "# dataloder\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-train\n",
    "vade = VaDE(args)\n",
    "if args.cuda:\n",
    "    vade.cuda()\n",
    "\n",
    "vade.pre_train(dataloader, pre_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m x, _ \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mcuda:\n\u001b[1;32m---> 14\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m     15\u001b[0m     loss \u001b[39m=\u001b[39m vade\u001b[39m.\u001b[39mELBO_loss(x)\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# train on elbo loss\n",
    "optimizer = Adam(vade.parameters(), lr=2e-3)\n",
    "lr_s = StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "writer=SummaryWriter()\n",
    "\n",
    "epoch_bar = tqdm(range(300))\n",
    "tsne = TSNE()\n",
    "\n",
    "for epoch in epoch_bar:\n",
    "    L = 0\n",
    "    for x, _ in dataloader:\n",
    "        if args.cuda:\n",
    "            x = x.cuda()\n",
    "        loss = vade.ELBO_loss(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_s.step()\n",
    "\n",
    "        L += loss.detach().cpu().numpy()\n",
    "\n",
    "    pre = []\n",
    "    tru = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            if args.cuda:\n",
    "                x = x.cuda()\n",
    "            \n",
    "            y = y.repeat_interleave(64)\n",
    "            tru.append(y.numpy())\n",
    "            pre.append(vade.predict(x))\n",
    "\n",
    "    tru = np.concatenate(tru, 0)\n",
    "    pre = np.concatenate(pre, 0)\n",
    "\n",
    "    writer.add_scalar('loss',L/len(dataloader),epoch)\n",
    "    writer.add_scalar('acc',cluster_acc(pre,tru)[0]*100,epoch)\n",
    "    writer.add_scalar('lr',lr_s.get_lr()[0],epoch)\n",
    "\n",
    "    epoch_bar.write('Loss={:.4f},ACC={:.4f}%,LR={:.4f}'.format(L/len(dataloader),cluster_acc(pre,tru)[0]*100,lr_s.get_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
