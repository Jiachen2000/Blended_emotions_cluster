{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jiachenyao/Desktop/Thesis/OpenFace_data/All_data_intensity_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 dataframes were deleted.\n",
      "905\n",
      "File with maximum rows: A205_mix_disg_sad_3070.csv\n",
      "Number of rows: 299\n"
     ]
    }
   ],
   "source": [
    "# Load data and extract features\n",
    "dfs = []\n",
    "num_deleted = 0\n",
    "\n",
    "max_rows = 0\n",
    "max_file = None\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "\n",
    "\n",
    "        # Check the ratio of rows with confidence >= 0.98 to the total number of rows\n",
    "        if len(df)>320 or len(df[df[\"confidence\"]<0.98])/len(df) >= 0.15:\n",
    "            # print the filename and delete the df variable\n",
    "            #print(filename)\n",
    "            del df\n",
    "            num_deleted += 1\n",
    "        else:\n",
    "            # Select confidence >= 0.98 & success = 1\n",
    "            df = df.loc[(df[\"confidence\"]>= 0.98) & (df[\"success\"]== 1 ) ] \n",
    "            # Drop columns that does not contain facial feature information\n",
    "            df = df.drop(columns=[\"confidence\",\"success\",\"frame\", \"face_id\", \"timestamp\"])\n",
    "            \n",
    "            # Drop binary AU features\n",
    "            cols_to_drop = df.filter(regex='AU.*_c').columns\n",
    "            df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "            # Feature selection\n",
    "            # 115 features, excluding 3D and eye\n",
    "            #df = df.iloc[:, np.concatenate([range(0, 8), range(288,294),range(299,306),range(311,321),range(325,330),\n",
    "                                            #range(342,362),range(367,374),range(379,389),range(393,398),\n",
    "                                            #range(410,430),range(674,691)])]\n",
    "\n",
    "            \n",
    "            # only mouth\n",
    "            df = df.iloc[:, np.concatenate([range(342,362), range(410,430),range(478,498),range(546,566),range(614,634)\n",
    "                                            ])]\n",
    "            \n",
    "\n",
    "            df = df.fillna(method='ffill') # Forward fill missing values\n",
    "            df = df.fillna(method='bfill') # Backward fill missing values\n",
    "\n",
    "            # Add a column to indicate the emotion\n",
    "            df.insert(0, 'emotion', os.path.splitext(os.path.basename(filepath))[0])\n",
    "            # Exclude actor id\n",
    "            df['emotion'] = df['emotion'].str.split('_', n=1, expand=True)[1]\n",
    "            \n",
    "            \n",
    "            num_rows = df.shape[0]\n",
    "            if num_rows > max_rows:\n",
    "                max_rows = num_rows\n",
    "                max_file = filename\n",
    "            \n",
    "            dfs.append(df)\n",
    "        \n",
    "print(f\"{num_deleted} dataframes were deleted.\")\n",
    "print(len(dfs))\n",
    "\n",
    "# Print file with maximum number of rows\n",
    "print(\"File with maximum rows:\", max_file)\n",
    "print(\"Number of rows:\", max_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion',\n",
       " 'x_48',\n",
       " 'x_49',\n",
       " 'x_50',\n",
       " 'x_51',\n",
       " 'x_52',\n",
       " 'x_53',\n",
       " 'x_54',\n",
       " 'x_55',\n",
       " 'x_56',\n",
       " 'x_57',\n",
       " 'x_58',\n",
       " 'x_59',\n",
       " 'x_60',\n",
       " 'x_61',\n",
       " 'x_62',\n",
       " 'x_63',\n",
       " 'x_64',\n",
       " 'x_65',\n",
       " 'x_66',\n",
       " 'x_67',\n",
       " 'y_48',\n",
       " 'y_49',\n",
       " 'y_50',\n",
       " 'y_51',\n",
       " 'y_52',\n",
       " 'y_53',\n",
       " 'y_54',\n",
       " 'y_55',\n",
       " 'y_56',\n",
       " 'y_57',\n",
       " 'y_58',\n",
       " 'y_59',\n",
       " 'y_60',\n",
       " 'y_61',\n",
       " 'y_62',\n",
       " 'y_63',\n",
       " 'y_64',\n",
       " 'y_65',\n",
       " 'y_66',\n",
       " 'y_67',\n",
       " 'X_48',\n",
       " 'X_49',\n",
       " 'X_50',\n",
       " 'X_51',\n",
       " 'X_52',\n",
       " 'X_53',\n",
       " 'X_54',\n",
       " 'X_55',\n",
       " 'X_56',\n",
       " 'X_57',\n",
       " 'X_58',\n",
       " 'X_59',\n",
       " 'X_60',\n",
       " 'X_61',\n",
       " 'X_62',\n",
       " 'X_63',\n",
       " 'X_64',\n",
       " 'X_65',\n",
       " 'X_66',\n",
       " 'X_67',\n",
       " 'Y_48',\n",
       " 'Y_49',\n",
       " 'Y_50',\n",
       " 'Y_51',\n",
       " 'Y_52',\n",
       " 'Y_53',\n",
       " 'Y_54',\n",
       " 'Y_55',\n",
       " 'Y_56',\n",
       " 'Y_57',\n",
       " 'Y_58',\n",
       " 'Y_59',\n",
       " 'Y_60',\n",
       " 'Y_61',\n",
       " 'Y_62',\n",
       " 'Y_63',\n",
       " 'Y_64',\n",
       " 'Y_65',\n",
       " 'Y_66',\n",
       " 'Y_67',\n",
       " 'Z_48',\n",
       " 'Z_49',\n",
       " 'Z_50',\n",
       " 'Z_51',\n",
       " 'Z_52',\n",
       " 'Z_53',\n",
       " 'Z_54',\n",
       " 'Z_55',\n",
       " 'Z_56',\n",
       " 'Z_57',\n",
       " 'Z_58',\n",
       " 'Z_59',\n",
       " 'Z_60',\n",
       " 'Z_61',\n",
       " 'Z_62',\n",
       " 'Z_63',\n",
       " 'Z_64',\n",
       " 'Z_65',\n",
       " 'Z_66',\n",
       " 'Z_67']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = dfs[1].columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>...</th>\n",
       "      <th>Z_58</th>\n",
       "      <th>Z_59</th>\n",
       "      <th>Z_60</th>\n",
       "      <th>Z_61</th>\n",
       "      <th>Z_62</th>\n",
       "      <th>Z_63</th>\n",
       "      <th>Z_64</th>\n",
       "      <th>Z_65</th>\n",
       "      <th>Z_66</th>\n",
       "      <th>Z_67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>913.1</td>\n",
       "      <td>927.9</td>\n",
       "      <td>946.0</td>\n",
       "      <td>962.4</td>\n",
       "      <td>981.3</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>1029.1</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>991.7</td>\n",
       "      <td>...</td>\n",
       "      <td>546.3</td>\n",
       "      <td>551.1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>547.5</td>\n",
       "      <td>545.2</td>\n",
       "      <td>545.0</td>\n",
       "      <td>554.4</td>\n",
       "      <td>545.1</td>\n",
       "      <td>545.4</td>\n",
       "      <td>547.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>911.7</td>\n",
       "      <td>926.3</td>\n",
       "      <td>944.5</td>\n",
       "      <td>961.4</td>\n",
       "      <td>981.0</td>\n",
       "      <td>1005.1</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>1011.5</td>\n",
       "      <td>991.4</td>\n",
       "      <td>...</td>\n",
       "      <td>545.7</td>\n",
       "      <td>550.5</td>\n",
       "      <td>559.4</td>\n",
       "      <td>546.7</td>\n",
       "      <td>544.3</td>\n",
       "      <td>544.3</td>\n",
       "      <td>553.6</td>\n",
       "      <td>544.7</td>\n",
       "      <td>544.9</td>\n",
       "      <td>547.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>911.2</td>\n",
       "      <td>926.0</td>\n",
       "      <td>944.3</td>\n",
       "      <td>961.1</td>\n",
       "      <td>980.6</td>\n",
       "      <td>1004.8</td>\n",
       "      <td>1028.4</td>\n",
       "      <td>1011.1</td>\n",
       "      <td>990.9</td>\n",
       "      <td>...</td>\n",
       "      <td>546.1</td>\n",
       "      <td>551.1</td>\n",
       "      <td>559.9</td>\n",
       "      <td>547.2</td>\n",
       "      <td>544.7</td>\n",
       "      <td>544.6</td>\n",
       "      <td>553.8</td>\n",
       "      <td>544.9</td>\n",
       "      <td>545.1</td>\n",
       "      <td>547.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>910.8</td>\n",
       "      <td>925.9</td>\n",
       "      <td>944.3</td>\n",
       "      <td>960.9</td>\n",
       "      <td>980.3</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>1028.2</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>990.6</td>\n",
       "      <td>...</td>\n",
       "      <td>549.2</td>\n",
       "      <td>554.3</td>\n",
       "      <td>562.9</td>\n",
       "      <td>550.2</td>\n",
       "      <td>547.8</td>\n",
       "      <td>547.6</td>\n",
       "      <td>556.8</td>\n",
       "      <td>547.9</td>\n",
       "      <td>548.2</td>\n",
       "      <td>550.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>910.9</td>\n",
       "      <td>926.0</td>\n",
       "      <td>944.3</td>\n",
       "      <td>960.9</td>\n",
       "      <td>980.3</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>990.6</td>\n",
       "      <td>...</td>\n",
       "      <td>549.0</td>\n",
       "      <td>553.9</td>\n",
       "      <td>562.5</td>\n",
       "      <td>550.1</td>\n",
       "      <td>547.7</td>\n",
       "      <td>547.5</td>\n",
       "      <td>556.6</td>\n",
       "      <td>547.7</td>\n",
       "      <td>547.9</td>\n",
       "      <td>550.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>911.6</td>\n",
       "      <td>926.0</td>\n",
       "      <td>944.3</td>\n",
       "      <td>960.8</td>\n",
       "      <td>979.9</td>\n",
       "      <td>1004.4</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>990.2</td>\n",
       "      <td>...</td>\n",
       "      <td>545.5</td>\n",
       "      <td>550.5</td>\n",
       "      <td>559.7</td>\n",
       "      <td>546.9</td>\n",
       "      <td>544.6</td>\n",
       "      <td>544.5</td>\n",
       "      <td>553.4</td>\n",
       "      <td>544.6</td>\n",
       "      <td>544.6</td>\n",
       "      <td>547.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>912.8</td>\n",
       "      <td>928.1</td>\n",
       "      <td>946.5</td>\n",
       "      <td>962.5</td>\n",
       "      <td>981.0</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>1027.9</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>991.1</td>\n",
       "      <td>...</td>\n",
       "      <td>546.4</td>\n",
       "      <td>551.1</td>\n",
       "      <td>560.1</td>\n",
       "      <td>547.6</td>\n",
       "      <td>545.4</td>\n",
       "      <td>545.6</td>\n",
       "      <td>555.1</td>\n",
       "      <td>545.7</td>\n",
       "      <td>545.6</td>\n",
       "      <td>547.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>914.1</td>\n",
       "      <td>929.3</td>\n",
       "      <td>948.0</td>\n",
       "      <td>963.4</td>\n",
       "      <td>981.2</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>991.9</td>\n",
       "      <td>...</td>\n",
       "      <td>539.8</td>\n",
       "      <td>544.8</td>\n",
       "      <td>554.9</td>\n",
       "      <td>541.5</td>\n",
       "      <td>539.5</td>\n",
       "      <td>539.7</td>\n",
       "      <td>550.2</td>\n",
       "      <td>539.6</td>\n",
       "      <td>539.4</td>\n",
       "      <td>541.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>915.8</td>\n",
       "      <td>930.3</td>\n",
       "      <td>949.3</td>\n",
       "      <td>963.6</td>\n",
       "      <td>979.9</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>1029.8</td>\n",
       "      <td>1011.5</td>\n",
       "      <td>990.8</td>\n",
       "      <td>...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>538.3</td>\n",
       "      <td>548.8</td>\n",
       "      <td>534.6</td>\n",
       "      <td>532.7</td>\n",
       "      <td>532.9</td>\n",
       "      <td>543.4</td>\n",
       "      <td>533.2</td>\n",
       "      <td>532.9</td>\n",
       "      <td>534.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>930.2</td>\n",
       "      <td>936.8</td>\n",
       "      <td>950.5</td>\n",
       "      <td>963.5</td>\n",
       "      <td>978.0</td>\n",
       "      <td>997.1</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>990.3</td>\n",
       "      <td>...</td>\n",
       "      <td>525.9</td>\n",
       "      <td>526.5</td>\n",
       "      <td>532.3</td>\n",
       "      <td>525.5</td>\n",
       "      <td>523.8</td>\n",
       "      <td>524.3</td>\n",
       "      <td>529.7</td>\n",
       "      <td>526.0</td>\n",
       "      <td>525.8</td>\n",
       "      <td>527.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>928.3</td>\n",
       "      <td>936.3</td>\n",
       "      <td>952.1</td>\n",
       "      <td>965.5</td>\n",
       "      <td>980.4</td>\n",
       "      <td>1001.6</td>\n",
       "      <td>1021.4</td>\n",
       "      <td>1009.4</td>\n",
       "      <td>993.6</td>\n",
       "      <td>...</td>\n",
       "      <td>525.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>534.4</td>\n",
       "      <td>525.2</td>\n",
       "      <td>523.3</td>\n",
       "      <td>523.9</td>\n",
       "      <td>531.2</td>\n",
       "      <td>525.1</td>\n",
       "      <td>524.8</td>\n",
       "      <td>526.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>930.3</td>\n",
       "      <td>938.0</td>\n",
       "      <td>954.1</td>\n",
       "      <td>968.0</td>\n",
       "      <td>983.3</td>\n",
       "      <td>1005.2</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>997.4</td>\n",
       "      <td>...</td>\n",
       "      <td>523.4</td>\n",
       "      <td>525.0</td>\n",
       "      <td>532.3</td>\n",
       "      <td>523.3</td>\n",
       "      <td>521.5</td>\n",
       "      <td>522.0</td>\n",
       "      <td>528.7</td>\n",
       "      <td>523.9</td>\n",
       "      <td>523.6</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>931.5</td>\n",
       "      <td>940.2</td>\n",
       "      <td>956.9</td>\n",
       "      <td>970.8</td>\n",
       "      <td>985.8</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>1029.6</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>1000.3</td>\n",
       "      <td>...</td>\n",
       "      <td>525.8</td>\n",
       "      <td>527.8</td>\n",
       "      <td>535.9</td>\n",
       "      <td>526.1</td>\n",
       "      <td>524.3</td>\n",
       "      <td>524.5</td>\n",
       "      <td>531.7</td>\n",
       "      <td>526.4</td>\n",
       "      <td>526.1</td>\n",
       "      <td>527.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>933.3</td>\n",
       "      <td>942.8</td>\n",
       "      <td>960.0</td>\n",
       "      <td>973.3</td>\n",
       "      <td>987.7</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1032.9</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1001.6</td>\n",
       "      <td>...</td>\n",
       "      <td>524.1</td>\n",
       "      <td>526.9</td>\n",
       "      <td>535.8</td>\n",
       "      <td>525.4</td>\n",
       "      <td>523.4</td>\n",
       "      <td>523.7</td>\n",
       "      <td>531.8</td>\n",
       "      <td>524.8</td>\n",
       "      <td>524.5</td>\n",
       "      <td>526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>935.6</td>\n",
       "      <td>945.2</td>\n",
       "      <td>962.7</td>\n",
       "      <td>976.0</td>\n",
       "      <td>990.5</td>\n",
       "      <td>1013.8</td>\n",
       "      <td>1035.2</td>\n",
       "      <td>1022.8</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>...</td>\n",
       "      <td>522.8</td>\n",
       "      <td>525.6</td>\n",
       "      <td>534.2</td>\n",
       "      <td>523.8</td>\n",
       "      <td>521.7</td>\n",
       "      <td>522.2</td>\n",
       "      <td>530.1</td>\n",
       "      <td>523.2</td>\n",
       "      <td>522.9</td>\n",
       "      <td>524.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>936.8</td>\n",
       "      <td>947.3</td>\n",
       "      <td>965.1</td>\n",
       "      <td>978.4</td>\n",
       "      <td>992.9</td>\n",
       "      <td>1016.2</td>\n",
       "      <td>1037.9</td>\n",
       "      <td>1025.3</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>...</td>\n",
       "      <td>527.1</td>\n",
       "      <td>530.0</td>\n",
       "      <td>538.6</td>\n",
       "      <td>528.0</td>\n",
       "      <td>525.9</td>\n",
       "      <td>526.3</td>\n",
       "      <td>534.5</td>\n",
       "      <td>527.5</td>\n",
       "      <td>527.2</td>\n",
       "      <td>528.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>938.3</td>\n",
       "      <td>949.4</td>\n",
       "      <td>967.5</td>\n",
       "      <td>981.0</td>\n",
       "      <td>995.6</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1040.7</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>...</td>\n",
       "      <td>530.2</td>\n",
       "      <td>533.2</td>\n",
       "      <td>541.9</td>\n",
       "      <td>531.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>529.4</td>\n",
       "      <td>537.7</td>\n",
       "      <td>530.6</td>\n",
       "      <td>530.2</td>\n",
       "      <td>531.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>940.3</td>\n",
       "      <td>951.4</td>\n",
       "      <td>969.8</td>\n",
       "      <td>983.6</td>\n",
       "      <td>998.5</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>1043.7</td>\n",
       "      <td>1030.7</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>...</td>\n",
       "      <td>529.0</td>\n",
       "      <td>532.2</td>\n",
       "      <td>541.3</td>\n",
       "      <td>530.6</td>\n",
       "      <td>528.6</td>\n",
       "      <td>529.0</td>\n",
       "      <td>536.8</td>\n",
       "      <td>529.6</td>\n",
       "      <td>529.2</td>\n",
       "      <td>530.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>941.9</td>\n",
       "      <td>953.6</td>\n",
       "      <td>971.7</td>\n",
       "      <td>985.8</td>\n",
       "      <td>1000.9</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1045.9</td>\n",
       "      <td>1032.6</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>...</td>\n",
       "      <td>527.6</td>\n",
       "      <td>531.1</td>\n",
       "      <td>540.4</td>\n",
       "      <td>529.4</td>\n",
       "      <td>527.4</td>\n",
       "      <td>528.0</td>\n",
       "      <td>536.1</td>\n",
       "      <td>528.3</td>\n",
       "      <td>527.8</td>\n",
       "      <td>529.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>943.8</td>\n",
       "      <td>956.5</td>\n",
       "      <td>975.0</td>\n",
       "      <td>988.8</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1026.7</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1034.7</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>...</td>\n",
       "      <td>529.4</td>\n",
       "      <td>533.2</td>\n",
       "      <td>543.2</td>\n",
       "      <td>531.4</td>\n",
       "      <td>529.5</td>\n",
       "      <td>530.4</td>\n",
       "      <td>539.1</td>\n",
       "      <td>530.6</td>\n",
       "      <td>529.8</td>\n",
       "      <td>531.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>946.2</td>\n",
       "      <td>959.0</td>\n",
       "      <td>977.4</td>\n",
       "      <td>991.1</td>\n",
       "      <td>1006.4</td>\n",
       "      <td>1028.9</td>\n",
       "      <td>1051.5</td>\n",
       "      <td>1036.1</td>\n",
       "      <td>1016.9</td>\n",
       "      <td>...</td>\n",
       "      <td>531.6</td>\n",
       "      <td>535.8</td>\n",
       "      <td>546.3</td>\n",
       "      <td>534.0</td>\n",
       "      <td>532.1</td>\n",
       "      <td>533.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>532.3</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>947.3</td>\n",
       "      <td>960.6</td>\n",
       "      <td>979.0</td>\n",
       "      <td>993.3</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1031.4</td>\n",
       "      <td>1053.5</td>\n",
       "      <td>1038.3</td>\n",
       "      <td>1019.2</td>\n",
       "      <td>...</td>\n",
       "      <td>539.2</td>\n",
       "      <td>543.4</td>\n",
       "      <td>553.3</td>\n",
       "      <td>541.5</td>\n",
       "      <td>539.5</td>\n",
       "      <td>540.3</td>\n",
       "      <td>548.8</td>\n",
       "      <td>540.2</td>\n",
       "      <td>539.5</td>\n",
       "      <td>541.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>948.4</td>\n",
       "      <td>962.4</td>\n",
       "      <td>981.0</td>\n",
       "      <td>995.2</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>1033.5</td>\n",
       "      <td>1056.1</td>\n",
       "      <td>1039.8</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>...</td>\n",
       "      <td>540.6</td>\n",
       "      <td>545.3</td>\n",
       "      <td>556.0</td>\n",
       "      <td>543.5</td>\n",
       "      <td>541.6</td>\n",
       "      <td>542.5</td>\n",
       "      <td>551.4</td>\n",
       "      <td>542.0</td>\n",
       "      <td>541.2</td>\n",
       "      <td>543.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>949.6</td>\n",
       "      <td>963.9</td>\n",
       "      <td>982.5</td>\n",
       "      <td>996.3</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>1034.2</td>\n",
       "      <td>1056.5</td>\n",
       "      <td>1040.4</td>\n",
       "      <td>1020.6</td>\n",
       "      <td>...</td>\n",
       "      <td>545.4</td>\n",
       "      <td>549.9</td>\n",
       "      <td>560.1</td>\n",
       "      <td>547.6</td>\n",
       "      <td>545.7</td>\n",
       "      <td>546.7</td>\n",
       "      <td>555.9</td>\n",
       "      <td>546.5</td>\n",
       "      <td>545.7</td>\n",
       "      <td>547.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>950.4</td>\n",
       "      <td>964.7</td>\n",
       "      <td>983.3</td>\n",
       "      <td>997.2</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1057.3</td>\n",
       "      <td>1040.9</td>\n",
       "      <td>1021.4</td>\n",
       "      <td>...</td>\n",
       "      <td>547.7</td>\n",
       "      <td>552.4</td>\n",
       "      <td>562.3</td>\n",
       "      <td>549.7</td>\n",
       "      <td>547.9</td>\n",
       "      <td>549.0</td>\n",
       "      <td>558.1</td>\n",
       "      <td>549.0</td>\n",
       "      <td>548.2</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>950.8</td>\n",
       "      <td>964.6</td>\n",
       "      <td>983.2</td>\n",
       "      <td>997.2</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>1035.1</td>\n",
       "      <td>1057.2</td>\n",
       "      <td>1041.6</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>...</td>\n",
       "      <td>553.8</td>\n",
       "      <td>557.9</td>\n",
       "      <td>567.4</td>\n",
       "      <td>554.9</td>\n",
       "      <td>553.1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>554.9</td>\n",
       "      <td>554.2</td>\n",
       "      <td>555.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>952.2</td>\n",
       "      <td>965.4</td>\n",
       "      <td>983.5</td>\n",
       "      <td>997.7</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1035.4</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1041.4</td>\n",
       "      <td>1022.2</td>\n",
       "      <td>...</td>\n",
       "      <td>553.5</td>\n",
       "      <td>557.6</td>\n",
       "      <td>566.8</td>\n",
       "      <td>554.8</td>\n",
       "      <td>552.9</td>\n",
       "      <td>554.0</td>\n",
       "      <td>562.8</td>\n",
       "      <td>554.8</td>\n",
       "      <td>554.1</td>\n",
       "      <td>555.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>953.2</td>\n",
       "      <td>966.0</td>\n",
       "      <td>983.8</td>\n",
       "      <td>998.2</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1035.8</td>\n",
       "      <td>1056.6</td>\n",
       "      <td>1041.7</td>\n",
       "      <td>1023.1</td>\n",
       "      <td>...</td>\n",
       "      <td>556.0</td>\n",
       "      <td>559.7</td>\n",
       "      <td>568.1</td>\n",
       "      <td>556.8</td>\n",
       "      <td>555.0</td>\n",
       "      <td>556.1</td>\n",
       "      <td>564.6</td>\n",
       "      <td>557.1</td>\n",
       "      <td>556.4</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>953.6</td>\n",
       "      <td>966.3</td>\n",
       "      <td>983.9</td>\n",
       "      <td>998.1</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1035.6</td>\n",
       "      <td>1056.1</td>\n",
       "      <td>1041.3</td>\n",
       "      <td>1022.7</td>\n",
       "      <td>...</td>\n",
       "      <td>559.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.3</td>\n",
       "      <td>559.9</td>\n",
       "      <td>557.9</td>\n",
       "      <td>559.1</td>\n",
       "      <td>568.0</td>\n",
       "      <td>559.9</td>\n",
       "      <td>559.2</td>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>953.5</td>\n",
       "      <td>966.1</td>\n",
       "      <td>983.6</td>\n",
       "      <td>997.7</td>\n",
       "      <td>1013.7</td>\n",
       "      <td>1034.9</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1040.5</td>\n",
       "      <td>1022.2</td>\n",
       "      <td>...</td>\n",
       "      <td>563.6</td>\n",
       "      <td>567.3</td>\n",
       "      <td>575.1</td>\n",
       "      <td>564.1</td>\n",
       "      <td>562.3</td>\n",
       "      <td>563.4</td>\n",
       "      <td>572.1</td>\n",
       "      <td>564.4</td>\n",
       "      <td>563.7</td>\n",
       "      <td>565.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>953.5</td>\n",
       "      <td>965.8</td>\n",
       "      <td>983.1</td>\n",
       "      <td>997.5</td>\n",
       "      <td>1013.6</td>\n",
       "      <td>1034.8</td>\n",
       "      <td>1054.4</td>\n",
       "      <td>1040.7</td>\n",
       "      <td>1022.6</td>\n",
       "      <td>...</td>\n",
       "      <td>565.8</td>\n",
       "      <td>569.2</td>\n",
       "      <td>576.9</td>\n",
       "      <td>566.2</td>\n",
       "      <td>564.3</td>\n",
       "      <td>565.4</td>\n",
       "      <td>573.7</td>\n",
       "      <td>566.3</td>\n",
       "      <td>565.7</td>\n",
       "      <td>567.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>953.5</td>\n",
       "      <td>965.6</td>\n",
       "      <td>983.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>1033.9</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1039.7</td>\n",
       "      <td>1021.6</td>\n",
       "      <td>...</td>\n",
       "      <td>566.8</td>\n",
       "      <td>570.3</td>\n",
       "      <td>578.4</td>\n",
       "      <td>567.3</td>\n",
       "      <td>565.5</td>\n",
       "      <td>566.6</td>\n",
       "      <td>575.1</td>\n",
       "      <td>567.6</td>\n",
       "      <td>566.9</td>\n",
       "      <td>568.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>952.8</td>\n",
       "      <td>965.3</td>\n",
       "      <td>982.7</td>\n",
       "      <td>996.5</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1033.3</td>\n",
       "      <td>1053.2</td>\n",
       "      <td>1039.1</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>567.5</td>\n",
       "      <td>571.2</td>\n",
       "      <td>579.1</td>\n",
       "      <td>568.1</td>\n",
       "      <td>566.3</td>\n",
       "      <td>567.3</td>\n",
       "      <td>575.8</td>\n",
       "      <td>568.0</td>\n",
       "      <td>567.4</td>\n",
       "      <td>569.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>952.7</td>\n",
       "      <td>965.3</td>\n",
       "      <td>982.6</td>\n",
       "      <td>996.2</td>\n",
       "      <td>1011.5</td>\n",
       "      <td>1032.6</td>\n",
       "      <td>1052.5</td>\n",
       "      <td>1038.2</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>...</td>\n",
       "      <td>569.1</td>\n",
       "      <td>572.9</td>\n",
       "      <td>580.9</td>\n",
       "      <td>570.3</td>\n",
       "      <td>568.5</td>\n",
       "      <td>569.5</td>\n",
       "      <td>577.5</td>\n",
       "      <td>570.0</td>\n",
       "      <td>569.4</td>\n",
       "      <td>571.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>953.4</td>\n",
       "      <td>965.5</td>\n",
       "      <td>982.3</td>\n",
       "      <td>996.2</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>1031.9</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1037.3</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>...</td>\n",
       "      <td>574.2</td>\n",
       "      <td>577.5</td>\n",
       "      <td>585.5</td>\n",
       "      <td>575.5</td>\n",
       "      <td>573.7</td>\n",
       "      <td>574.7</td>\n",
       "      <td>581.8</td>\n",
       "      <td>575.2</td>\n",
       "      <td>574.6</td>\n",
       "      <td>576.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>952.8</td>\n",
       "      <td>965.1</td>\n",
       "      <td>982.1</td>\n",
       "      <td>995.8</td>\n",
       "      <td>1011.3</td>\n",
       "      <td>1031.5</td>\n",
       "      <td>1050.8</td>\n",
       "      <td>1036.8</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>...</td>\n",
       "      <td>571.7</td>\n",
       "      <td>575.0</td>\n",
       "      <td>583.5</td>\n",
       "      <td>573.3</td>\n",
       "      <td>571.6</td>\n",
       "      <td>572.6</td>\n",
       "      <td>580.1</td>\n",
       "      <td>572.8</td>\n",
       "      <td>572.1</td>\n",
       "      <td>573.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>952.2</td>\n",
       "      <td>964.6</td>\n",
       "      <td>981.7</td>\n",
       "      <td>995.1</td>\n",
       "      <td>1010.4</td>\n",
       "      <td>1030.8</td>\n",
       "      <td>1050.5</td>\n",
       "      <td>1035.9</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>...</td>\n",
       "      <td>574.4</td>\n",
       "      <td>578.1</td>\n",
       "      <td>586.9</td>\n",
       "      <td>576.1</td>\n",
       "      <td>574.4</td>\n",
       "      <td>575.4</td>\n",
       "      <td>583.6</td>\n",
       "      <td>575.5</td>\n",
       "      <td>574.7</td>\n",
       "      <td>576.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>951.1</td>\n",
       "      <td>964.0</td>\n",
       "      <td>981.2</td>\n",
       "      <td>994.6</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>1030.1</td>\n",
       "      <td>1049.5</td>\n",
       "      <td>1035.2</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>...</td>\n",
       "      <td>578.8</td>\n",
       "      <td>582.4</td>\n",
       "      <td>590.9</td>\n",
       "      <td>580.3</td>\n",
       "      <td>578.6</td>\n",
       "      <td>579.6</td>\n",
       "      <td>587.2</td>\n",
       "      <td>579.9</td>\n",
       "      <td>579.2</td>\n",
       "      <td>580.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>950.6</td>\n",
       "      <td>963.2</td>\n",
       "      <td>980.5</td>\n",
       "      <td>994.0</td>\n",
       "      <td>1009.4</td>\n",
       "      <td>1029.8</td>\n",
       "      <td>1049.2</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>...</td>\n",
       "      <td>579.1</td>\n",
       "      <td>582.8</td>\n",
       "      <td>591.3</td>\n",
       "      <td>580.5</td>\n",
       "      <td>578.7</td>\n",
       "      <td>579.8</td>\n",
       "      <td>587.8</td>\n",
       "      <td>580.0</td>\n",
       "      <td>579.3</td>\n",
       "      <td>581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>949.8</td>\n",
       "      <td>962.2</td>\n",
       "      <td>979.9</td>\n",
       "      <td>993.1</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1028.9</td>\n",
       "      <td>1048.6</td>\n",
       "      <td>1034.5</td>\n",
       "      <td>1016.9</td>\n",
       "      <td>...</td>\n",
       "      <td>579.2</td>\n",
       "      <td>582.9</td>\n",
       "      <td>591.3</td>\n",
       "      <td>580.1</td>\n",
       "      <td>578.4</td>\n",
       "      <td>579.4</td>\n",
       "      <td>587.7</td>\n",
       "      <td>579.8</td>\n",
       "      <td>579.1</td>\n",
       "      <td>580.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>948.1</td>\n",
       "      <td>961.3</td>\n",
       "      <td>979.7</td>\n",
       "      <td>992.6</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>1028.2</td>\n",
       "      <td>1048.2</td>\n",
       "      <td>1033.9</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>580.7</td>\n",
       "      <td>584.8</td>\n",
       "      <td>593.4</td>\n",
       "      <td>581.0</td>\n",
       "      <td>579.4</td>\n",
       "      <td>580.5</td>\n",
       "      <td>590.1</td>\n",
       "      <td>581.4</td>\n",
       "      <td>580.6</td>\n",
       "      <td>582.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>946.9</td>\n",
       "      <td>961.0</td>\n",
       "      <td>979.7</td>\n",
       "      <td>992.4</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>1028.1</td>\n",
       "      <td>1048.6</td>\n",
       "      <td>1034.1</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>583.5</td>\n",
       "      <td>588.2</td>\n",
       "      <td>597.2</td>\n",
       "      <td>584.0</td>\n",
       "      <td>582.2</td>\n",
       "      <td>583.3</td>\n",
       "      <td>593.6</td>\n",
       "      <td>584.2</td>\n",
       "      <td>583.5</td>\n",
       "      <td>585.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>945.3</td>\n",
       "      <td>959.9</td>\n",
       "      <td>979.0</td>\n",
       "      <td>991.8</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>1027.8</td>\n",
       "      <td>1048.3</td>\n",
       "      <td>1033.9</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>...</td>\n",
       "      <td>584.7</td>\n",
       "      <td>589.2</td>\n",
       "      <td>598.1</td>\n",
       "      <td>584.7</td>\n",
       "      <td>583.1</td>\n",
       "      <td>584.3</td>\n",
       "      <td>594.9</td>\n",
       "      <td>585.5</td>\n",
       "      <td>584.6</td>\n",
       "      <td>586.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>944.0</td>\n",
       "      <td>959.4</td>\n",
       "      <td>978.8</td>\n",
       "      <td>991.4</td>\n",
       "      <td>1005.8</td>\n",
       "      <td>1027.3</td>\n",
       "      <td>1048.1</td>\n",
       "      <td>1033.4</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>...</td>\n",
       "      <td>587.4</td>\n",
       "      <td>592.2</td>\n",
       "      <td>601.4</td>\n",
       "      <td>587.1</td>\n",
       "      <td>585.6</td>\n",
       "      <td>586.8</td>\n",
       "      <td>598.6</td>\n",
       "      <td>588.1</td>\n",
       "      <td>587.2</td>\n",
       "      <td>588.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>942.8</td>\n",
       "      <td>957.9</td>\n",
       "      <td>977.3</td>\n",
       "      <td>990.7</td>\n",
       "      <td>1005.8</td>\n",
       "      <td>1027.5</td>\n",
       "      <td>1048.6</td>\n",
       "      <td>1033.7</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>...</td>\n",
       "      <td>585.1</td>\n",
       "      <td>590.1</td>\n",
       "      <td>599.7</td>\n",
       "      <td>585.5</td>\n",
       "      <td>583.8</td>\n",
       "      <td>585.1</td>\n",
       "      <td>596.4</td>\n",
       "      <td>586.1</td>\n",
       "      <td>585.2</td>\n",
       "      <td>586.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>941.7</td>\n",
       "      <td>957.2</td>\n",
       "      <td>976.4</td>\n",
       "      <td>989.9</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>1026.9</td>\n",
       "      <td>1047.5</td>\n",
       "      <td>1032.6</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>...</td>\n",
       "      <td>586.7</td>\n",
       "      <td>592.0</td>\n",
       "      <td>601.5</td>\n",
       "      <td>587.2</td>\n",
       "      <td>585.5</td>\n",
       "      <td>586.9</td>\n",
       "      <td>599.0</td>\n",
       "      <td>587.7</td>\n",
       "      <td>586.9</td>\n",
       "      <td>588.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mix_ang_fea_3070</td>\n",
       "      <td>940.8</td>\n",
       "      <td>956.3</td>\n",
       "      <td>975.8</td>\n",
       "      <td>989.5</td>\n",
       "      <td>1005.2</td>\n",
       "      <td>1026.7</td>\n",
       "      <td>1047.4</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>...</td>\n",
       "      <td>586.6</td>\n",
       "      <td>591.6</td>\n",
       "      <td>601.3</td>\n",
       "      <td>586.9</td>\n",
       "      <td>585.2</td>\n",
       "      <td>586.6</td>\n",
       "      <td>598.4</td>\n",
       "      <td>587.6</td>\n",
       "      <td>586.7</td>\n",
       "      <td>588.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             emotion   x_48   x_49   x_50   x_51    x_52    x_53    x_54   \n",
       "0   mix_ang_fea_3070  913.1  927.9  946.0  962.4   981.3  1005.6  1029.1  \\\n",
       "1   mix_ang_fea_3070  911.7  926.3  944.5  961.4   981.0  1005.1  1028.5   \n",
       "2   mix_ang_fea_3070  911.2  926.0  944.3  961.1   980.6  1004.8  1028.4   \n",
       "3   mix_ang_fea_3070  910.8  925.9  944.3  960.9   980.3  1004.6  1028.2   \n",
       "4   mix_ang_fea_3070  910.9  926.0  944.3  960.9   980.3  1004.5  1028.0   \n",
       "5   mix_ang_fea_3070  911.6  926.0  944.3  960.8   979.9  1004.4  1028.5   \n",
       "6   mix_ang_fea_3070  912.8  928.1  946.5  962.5   981.0  1004.5  1027.9   \n",
       "7   mix_ang_fea_3070  914.1  929.3  948.0  963.4   981.2  1005.0  1029.0   \n",
       "8   mix_ang_fea_3070  915.8  930.3  949.3  963.6   979.9  1004.5  1029.8   \n",
       "9   mix_ang_fea_3070  930.2  936.8  950.5  963.5   978.0   997.1  1014.6   \n",
       "10  mix_ang_fea_3070  928.3  936.3  952.1  965.5   980.4  1001.6  1021.4   \n",
       "11  mix_ang_fea_3070  930.3  938.0  954.1  968.0   983.3  1005.2  1025.2   \n",
       "12  mix_ang_fea_3070  931.5  940.2  956.9  970.8   985.8  1008.7  1029.6   \n",
       "13  mix_ang_fea_3070  933.3  942.8  960.0  973.3   987.7  1011.0  1032.9   \n",
       "14  mix_ang_fea_3070  935.6  945.2  962.7  976.0   990.5  1013.8  1035.2   \n",
       "15  mix_ang_fea_3070  936.8  947.3  965.1  978.4   992.9  1016.2  1037.9   \n",
       "16  mix_ang_fea_3070  938.3  949.4  967.5  981.0   995.6  1019.0  1040.7   \n",
       "17  mix_ang_fea_3070  940.3  951.4  969.8  983.6   998.5  1021.8  1043.7   \n",
       "18  mix_ang_fea_3070  941.9  953.6  971.7  985.8  1000.9  1024.0  1045.9   \n",
       "19  mix_ang_fea_3070  943.8  956.5  975.0  988.8  1004.0  1026.7  1049.0   \n",
       "20  mix_ang_fea_3070  946.2  959.0  977.4  991.1  1006.4  1028.9  1051.5   \n",
       "21  mix_ang_fea_3070  947.3  960.6  979.0  993.3  1009.1  1031.4  1053.5   \n",
       "22  mix_ang_fea_3070  948.4  962.4  981.0  995.2  1011.0  1033.5  1056.1   \n",
       "23  mix_ang_fea_3070  949.6  963.9  982.5  996.3  1011.7  1034.2  1056.5   \n",
       "24  mix_ang_fea_3070  950.4  964.7  983.3  997.2  1012.9  1035.0  1057.3   \n",
       "25  mix_ang_fea_3070  950.8  964.6  983.2  997.2  1012.6  1035.1  1057.2   \n",
       "26  mix_ang_fea_3070  952.2  965.4  983.5  997.7  1013.4  1035.4  1057.0   \n",
       "27  mix_ang_fea_3070  953.2  966.0  983.8  998.2  1014.2  1035.8  1056.6   \n",
       "28  mix_ang_fea_3070  953.6  966.3  983.9  998.1  1014.2  1035.6  1056.1   \n",
       "29  mix_ang_fea_3070  953.5  966.1  983.6  997.7  1013.7  1034.9  1055.0   \n",
       "30  mix_ang_fea_3070  953.5  965.8  983.1  997.5  1013.6  1034.8  1054.4   \n",
       "31  mix_ang_fea_3070  953.5  965.6  983.0  997.0  1012.6  1033.9  1054.0   \n",
       "32  mix_ang_fea_3070  952.8  965.3  982.7  996.5  1012.1  1033.3  1053.2   \n",
       "33  mix_ang_fea_3070  952.7  965.3  982.6  996.2  1011.5  1032.6  1052.5   \n",
       "34  mix_ang_fea_3070  953.4  965.5  982.3  996.2  1011.8  1031.9  1051.0   \n",
       "35  mix_ang_fea_3070  952.8  965.1  982.1  995.8  1011.3  1031.5  1050.8   \n",
       "36  mix_ang_fea_3070  952.2  964.6  981.7  995.1  1010.4  1030.8  1050.5   \n",
       "37  mix_ang_fea_3070  951.1  964.0  981.2  994.6  1009.7  1030.1  1049.5   \n",
       "38  mix_ang_fea_3070  950.6  963.2  980.5  994.0  1009.4  1029.8  1049.2   \n",
       "39  mix_ang_fea_3070  949.8  962.2  979.9  993.1  1008.0  1028.9  1048.6   \n",
       "40  mix_ang_fea_3070  948.1  961.3  979.7  992.6  1007.1  1028.2  1048.2   \n",
       "41  mix_ang_fea_3070  946.9  961.0  979.7  992.4  1006.7  1028.1  1048.6   \n",
       "42  mix_ang_fea_3070  945.3  959.9  979.0  991.8  1006.3  1027.8  1048.3   \n",
       "43  mix_ang_fea_3070  944.0  959.4  978.8  991.4  1005.8  1027.3  1048.1   \n",
       "44  mix_ang_fea_3070  942.8  957.9  977.3  990.7  1005.8  1027.5  1048.6   \n",
       "45  mix_ang_fea_3070  941.7  957.2  976.4  989.9  1005.4  1026.9  1047.5   \n",
       "46  mix_ang_fea_3070  940.8  956.3  975.8  989.5  1005.2  1026.7  1047.4   \n",
       "\n",
       "      x_55    x_56  ...   Z_58   Z_59   Z_60   Z_61   Z_62   Z_63   Z_64   \n",
       "0   1012.0   991.7  ...  546.3  551.1  560.0  547.5  545.2  545.0  554.4  \\\n",
       "1   1011.5   991.4  ...  545.7  550.5  559.4  546.7  544.3  544.3  553.6   \n",
       "2   1011.1   990.9  ...  546.1  551.1  559.9  547.2  544.7  544.6  553.8   \n",
       "3   1011.0   990.6  ...  549.2  554.3  562.9  550.2  547.8  547.6  556.8   \n",
       "4   1010.8   990.6  ...  549.0  553.9  562.5  550.1  547.7  547.5  556.6   \n",
       "5   1010.7   990.2  ...  545.5  550.5  559.7  546.9  544.6  544.5  553.4   \n",
       "6   1010.7   991.1  ...  546.4  551.1  560.1  547.6  545.4  545.6  555.1   \n",
       "7   1011.7   991.9  ...  539.8  544.8  554.9  541.5  539.5  539.7  550.2   \n",
       "8   1011.5   990.8  ...  533.0  538.3  548.8  534.6  532.7  532.9  543.4   \n",
       "9   1004.0   990.3  ...  525.9  526.5  532.3  525.5  523.8  524.3  529.7   \n",
       "10  1009.4   993.6  ...  525.0  527.0  534.4  525.2  523.3  523.9  531.2   \n",
       "11  1013.9   997.4  ...  523.4  525.0  532.3  523.3  521.5  522.0  528.7   \n",
       "12  1017.8  1000.3  ...  525.8  527.8  535.9  526.1  524.3  524.5  531.7   \n",
       "13  1020.0  1001.6  ...  524.1  526.9  535.8  525.4  523.4  523.7  531.8   \n",
       "14  1022.8  1004.5  ...  522.8  525.6  534.2  523.8  521.7  522.2  530.1   \n",
       "15  1025.3  1006.7  ...  527.1  530.0  538.6  528.0  525.9  526.3  534.5   \n",
       "16  1028.0  1009.0  ...  530.2  533.2  541.9  531.0  529.0  529.4  537.7   \n",
       "17  1030.7  1011.7  ...  529.0  532.2  541.3  530.6  528.6  529.0  536.8   \n",
       "18  1032.6  1013.9  ...  527.6  531.1  540.4  529.4  527.4  528.0  536.1   \n",
       "19  1034.7  1015.7  ...  529.4  533.2  543.2  531.4  529.5  530.4  539.1   \n",
       "20  1036.1  1016.9  ...  531.6  535.8  546.3  534.0  532.1  533.0  542.0   \n",
       "21  1038.3  1019.2  ...  539.2  543.4  553.3  541.5  539.5  540.3  548.8   \n",
       "22  1039.8  1020.1  ...  540.6  545.3  556.0  543.5  541.6  542.5  551.4   \n",
       "23  1040.4  1020.6  ...  545.4  549.9  560.1  547.6  545.7  546.7  555.9   \n",
       "24  1040.9  1021.4  ...  547.7  552.4  562.3  549.7  547.9  549.0  558.1   \n",
       "25  1041.6  1022.0  ...  553.8  557.9  567.4  554.9  553.1  554.0  563.0   \n",
       "26  1041.4  1022.2  ...  553.5  557.6  566.8  554.8  552.9  554.0  562.8   \n",
       "27  1041.7  1023.1  ...  556.0  559.7  568.1  556.8  555.0  556.1  564.6   \n",
       "28  1041.3  1022.7  ...  559.0  563.0  571.3  559.9  557.9  559.1  568.0   \n",
       "29  1040.5  1022.2  ...  563.6  567.3  575.1  564.1  562.3  563.4  572.1   \n",
       "30  1040.7  1022.6  ...  565.8  569.2  576.9  566.2  564.3  565.4  573.7   \n",
       "31  1039.7  1021.6  ...  566.8  570.3  578.4  567.3  565.5  566.6  575.1   \n",
       "32  1039.1  1021.0  ...  567.5  571.2  579.1  568.1  566.3  567.3  575.8   \n",
       "33  1038.2  1020.1  ...  569.1  572.9  580.9  570.3  568.5  569.5  577.5   \n",
       "34  1037.3  1020.3  ...  574.2  577.5  585.5  575.5  573.7  574.7  581.8   \n",
       "35  1036.8  1019.5  ...  571.7  575.0  583.5  573.3  571.6  572.6  580.1   \n",
       "36  1035.9  1018.3  ...  574.4  578.1  586.9  576.1  574.4  575.4  583.6   \n",
       "37  1035.2  1017.8  ...  578.8  582.4  590.9  580.3  578.6  579.6  587.2   \n",
       "38  1035.0  1017.4  ...  579.1  582.8  591.3  580.5  578.7  579.8  587.8   \n",
       "39  1034.5  1016.9  ...  579.2  582.9  591.3  580.1  578.4  579.4  587.7   \n",
       "40  1033.9  1016.0  ...  580.7  584.8  593.4  581.0  579.4  580.5  590.1   \n",
       "41  1034.1  1016.0  ...  583.5  588.2  597.2  584.0  582.2  583.3  593.6   \n",
       "42  1033.9  1015.8  ...  584.7  589.2  598.1  584.7  583.1  584.3  594.9   \n",
       "43  1033.4  1015.2  ...  587.4  592.2  601.4  587.1  585.6  586.8  598.6   \n",
       "44  1033.7  1015.3  ...  585.1  590.1  599.7  585.5  583.8  585.1  596.4   \n",
       "45  1032.6  1014.2  ...  586.7  592.0  601.5  587.2  585.5  586.9  599.0   \n",
       "46  1032.4  1014.0  ...  586.6  591.6  601.3  586.9  585.2  586.6  598.4   \n",
       "\n",
       "     Z_65   Z_66   Z_67  \n",
       "0   545.1  545.4  547.9  \n",
       "1   544.7  544.9  547.3  \n",
       "2   544.9  545.1  547.7  \n",
       "3   547.9  548.2  550.8  \n",
       "4   547.7  547.9  550.5  \n",
       "5   544.6  544.6  547.1  \n",
       "6   545.7  545.6  547.9  \n",
       "7   539.6  539.4  541.6  \n",
       "8   533.2  532.9  534.9  \n",
       "9   526.0  525.8  527.3  \n",
       "10  525.1  524.8  526.4  \n",
       "11  523.9  523.6  525.0  \n",
       "12  526.4  526.1  527.5  \n",
       "13  524.8  524.5  526.0  \n",
       "14  523.2  522.9  524.5  \n",
       "15  527.5  527.2  528.8  \n",
       "16  530.6  530.2  531.8  \n",
       "17  529.6  529.2  530.8  \n",
       "18  528.3  527.8  529.5  \n",
       "19  530.6  529.8  531.4  \n",
       "20  533.0  532.3  534.0  \n",
       "21  540.2  539.5  541.4  \n",
       "22  542.0  541.2  543.1  \n",
       "23  546.5  545.7  547.5  \n",
       "24  549.0  548.2  550.0  \n",
       "25  554.9  554.2  555.7  \n",
       "26  554.8  554.1  555.7  \n",
       "27  557.1  556.4  558.0  \n",
       "28  559.9  559.2  561.0  \n",
       "29  564.4  563.7  565.4  \n",
       "30  566.3  565.7  567.4  \n",
       "31  567.6  566.9  568.5  \n",
       "32  568.0  567.4  569.1  \n",
       "33  570.0  569.4  571.1  \n",
       "34  575.2  574.6  576.3  \n",
       "35  572.8  572.1  573.7  \n",
       "36  575.5  574.7  576.4  \n",
       "37  579.9  579.2  580.8  \n",
       "38  580.0  579.3  581.0  \n",
       "39  579.8  579.1  580.6  \n",
       "40  581.4  580.6  582.1  \n",
       "41  584.2  583.5  585.1  \n",
       "42  585.5  584.6  586.1  \n",
       "43  588.1  587.2  588.7  \n",
       "44  586.1  585.2  586.8  \n",
       "45  587.7  586.9  588.6  \n",
       "46  587.6  586.7  588.3  \n",
       "\n",
       "[47 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  7., 21., 33., 40., 44., 37., 35., 38., 38., 31., 29., 41.,\n",
       "        50., 55., 41., 41., 34., 40., 40., 34., 29., 32., 36., 27., 20.,\n",
       "        14., 10.,  4.,  0.,  0.,  1.,  1.,  2.,  0.,  1.,  0.,  1.,  1.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([ 33. ,  42.3,  51.6,  60.9,  70.2,  79.5,  88.8,  98.1, 107.4,\n",
       "        116.7, 126. , 135.3, 144.6, 153.9, 163.2, 172.5, 181.8, 191.1,\n",
       "        200.4, 209.7, 219. , 228.3, 237.6, 246.9, 256.2, 265.5, 274.8,\n",
       "        284.1, 293.4, 302.7, 312. , 321.3, 330.6, 339.9, 349.2, 358.5,\n",
       "        367.8, 377.1, 386.4, 395.7, 405. , 414.3, 423.6, 432.9, 442.2,\n",
       "        451.5, 460.8, 470.1, 479.4, 488.7, 498. , 507.3, 516.6, 525.9,\n",
       "        535.2, 544.5, 553.8, 563.1, 572.4, 581.7, 591. , 600.3, 609.6,\n",
       "        618.9, 628.2, 637.5, 646.8, 656.1, 665.4, 674.7, 684. , 693.3,\n",
       "        702.6, 711.9, 721.2, 730.5, 739.8, 749.1, 758.4, 767.7, 777. ,\n",
       "        786.3, 795.6, 804.9, 814.2, 823.5, 832.8, 842.1, 851.4, 860.7,\n",
       "        870. , 879.3, 888.6, 897.9, 907.2, 916.5, 925.8, 935.1, 944.4,\n",
       "        953.7, 963. ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_len = [len(df) for df in dfs]\n",
    "\n",
    "plt.hist(dfs_len, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "for df in dfs:\n",
    "    cols_to_normalize = df.columns.difference(['emotion'])\n",
    "    #df[cols_to_normalize] = df[cols_to_normalize].apply(lambda x: (x - x.min()) / (x.max() - x.min())) # mix-max normalization\n",
    "    df[cols_to_normalize] = df[cols_to_normalize].apply(lambda x: (x - x.mean()) / x.std()) # Z normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change emotion name\n",
    "emotions = []\n",
    "\n",
    "for df in dfs:\n",
    "    emotion = df['emotion'].unique()\n",
    "    emotion = emotion[0]\n",
    "    if emotion.startswith('mix'):\n",
    "        emotion = emotion.rsplit(\"_\", 1)[0]\n",
    "    else:\n",
    "        emotion = emotion.split(\"_\", 1)[0]\n",
    "    df['emotion'] = emotion\n",
    "    emotions.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_list = label_encoder.fit_transform(emotions)\n",
    "label_mapping = dict(zip(label_list, emotions))\n",
    "\n",
    "emo_labels = []\n",
    "for df in dfs:\n",
    "    emotion = df['emotion'].iloc[0]\n",
    "    label = label_encoder.transform([emotion])[0]\n",
    "    emo_labels.extend([label] * len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "num_files = len(dfs)\n",
    "\n",
    "# Combine dataframes into a single tensor\n",
    "data = torch.zeros((num_files, max_rows, num_features))  # 1e-6 is added to avoid log(0)\n",
    "labels = torch.zeros((num_files, max_rows), dtype=torch.long) - 1 # -1 indicates missing values\n",
    "for i, df in enumerate(dfs):\n",
    "    encoded_labels = label_list[i]  # Convert non-numeric labels to numeric labels\n",
    "    data[i, : df.shape[0]] = torch.tensor(df.iloc[:,1:101].values, dtype=torch.float32)  # Exclude the first column (labels)\n",
    "    labels[i, : df.shape[0]] = torch.tensor(encoded_labels, dtype=torch.long)  # Use the encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([905, 299])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "# load dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module: nn.Module, batch_first: bool = True):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        # We have to reshape Y\n",
    "        if self.batch_first:\n",
    "            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n",
    "        else:\n",
    "            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeVAE_base(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(TimeVAE_base, self).__init__()\n",
    "        # encoder layers\n",
    "        self.encoder_convs = nn.Sequential(\n",
    "            nn.Conv1d(299, 128, 3, stride=2, padding=1,bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(128, 64, 3, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "        \n",
    "        ) # output shape: (batch_size, 64, 45)\n",
    "        self.fc1 = nn.Linear(25, 16)\n",
    "        self.mean = nn.Linear(16, latent_dim)\n",
    "        self.var = nn.Linear(16, latent_dim)\n",
    "\n",
    "        # decoder layers\n",
    "        self.fc2 = nn.Linear(latent_dim, 16)\n",
    "        self.fc3 = nn.Linear(16, 25)\n",
    "        self.decoder_convs = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 128, 3, stride=2, padding=1,output_padding=1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(128, 299, 3, stride=2, padding=1,output_padding=1 ,bias=False),\n",
    "            nn.ReLU(True)\n",
    "        ) # output shape: (batch_size, 963, 288)\n",
    "\n",
    "        self.time_distributed = TimeDistributed(nn.Linear(100, 100))\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoder_convs(x)\n",
    "        x = x.contiguous().view(-1, x.size(-1)) # flatten\n",
    "        x = self.fc1(x)\n",
    "        mean = self.mean(x)\n",
    "        log_var = self.var(x)\n",
    "        return mean, log_var\n",
    "    \n",
    "    def reparaterize(self, mean, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps*std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        z = self.fc2(z)\n",
    "        z = self.fc3(z)\n",
    "        z = z.contiguous().view(-1, 64, 25) # reshape\n",
    "        z = self.decoder_convs(z)\n",
    "        z = self.time_distributed(z)\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encode(x)\n",
    "        z = self.reparaterize(mean, log_var)\n",
    "        return self.decode(z), mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE loss function\n",
    "def vae_loss(x, x_recon, mean, log_var, beta=1):\n",
    "    recon_loss = nn.MSELoss()(x_recon, x)\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return recon_loss + kl_loss * beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VAE model, optimizer, and other settings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_dim = 2\n",
    "model = TimeVAE_base(latent_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_vae(epochs, train_loader, val_loader, model, optimizer):\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_data, _ in tqdm(train_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mean, log_var = model(batch_data)\n",
    "            loss = vae_loss(batch_data, x_recon, mean, log_var, beta=2) # beta_VAE\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            loss_history.append(loss.item())\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_data, _ in val_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                x_recon, mean, log_var = model(batch_data)\n",
    "                loss = vae_loss(batch_data, x_recon, mean, log_var, beta=2) # beta_VAE\n",
    "                val_loss += loss.item()\n",
    "            \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # plot the training loss curve\n",
    "    plt.plot(loss_history)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.xlim((2,50)) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 5.9586\n",
      "Epoch 1, Val Loss: 1.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.7175\n",
      "Epoch 2, Val Loss: 0.3850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.2783\n",
      "Epoch 3, Val Loss: 0.2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.1411\n",
      "Epoch 4, Val Loss: 0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.1166\n",
      "Epoch 5, Val Loss: 0.1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.1082\n",
      "Epoch 6, Val Loss: 0.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0807\n",
      "Epoch 7, Val Loss: 0.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0675\n",
      "Epoch 8, Val Loss: 0.1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0633\n",
      "Epoch 9, Val Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0619\n",
      "Epoch 10, Val Loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.0582\n",
      "Epoch 11, Val Loss: 0.0960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.0612\n",
      "Epoch 12, Val Loss: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.0595\n",
      "Epoch 13, Val Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.0559\n",
      "Epoch 14, Val Loss: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.0502\n",
      "Epoch 15, Val Loss: 0.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.0430\n",
      "Epoch 16, Val Loss: 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.0402\n",
      "Epoch 17, Val Loss: 0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.0367\n",
      "Epoch 18, Val Loss: 0.0639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.0360\n",
      "Epoch 19, Val Loss: 0.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.0359\n",
      "Epoch 20, Val Loss: 0.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 0.0355\n",
      "Epoch 21, Val Loss: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 0.0342\n",
      "Epoch 22, Val Loss: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 0.0335\n",
      "Epoch 23, Val Loss: 0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.0329\n",
      "Epoch 24, Val Loss: 0.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.0339\n",
      "Epoch 25, Val Loss: 0.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 0.0346\n",
      "Epoch 26, Val Loss: 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 0.0330\n",
      "Epoch 27, Val Loss: 0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 0.0313\n",
      "Epoch 28, Val Loss: 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 0.0305\n",
      "Epoch 29, Val Loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train Loss: 0.0287\n",
      "Epoch 30, Val Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 21.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train Loss: 0.0268\n",
      "Epoch 31, Val Loss: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 0.0268\n",
      "Epoch 32, Val Loss: 0.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train Loss: 0.0263\n",
      "Epoch 33, Val Loss: 0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train Loss: 0.0284\n",
      "Epoch 34, Val Loss: 0.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train Loss: 0.0269\n",
      "Epoch 35, Val Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train Loss: 0.0257\n",
      "Epoch 36, Val Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train Loss: 0.0261\n",
      "Epoch 37, Val Loss: 0.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train Loss: 0.0271\n",
      "Epoch 38, Val Loss: 0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train Loss: 0.0254\n",
      "Epoch 39, Val Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train Loss: 0.0241\n",
      "Epoch 40, Val Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Train Loss: 0.0234\n",
      "Epoch 41, Val Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Train Loss: 0.0233\n",
      "Epoch 42, Val Loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Train Loss: 0.0232\n",
      "Epoch 43, Val Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train Loss: 0.0222\n",
      "Epoch 44, Val Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Train Loss: 0.0219\n",
      "Epoch 45, Val Loss: 0.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Train Loss: 0.0220\n",
      "Epoch 46, Val Loss: 0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Train Loss: 0.0218\n",
      "Epoch 47, Val Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train Loss: 0.0218\n",
      "Epoch 48, Val Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Train Loss: 0.0217\n",
      "Epoch 49, Val Loss: 0.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:00<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train Loss: 0.0214\n",
      "Epoch 50, Val Loss: 0.0430\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_vae(epochs, train_loader, val_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_space(vae, data_loader):\n",
    "    latent_space = []\n",
    "    labels = []\n",
    "\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in data_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            mean, log_var = vae.encode(batch_data)\n",
    "            z = vae.reparaterize(mean, log_var)\n",
    "            latent_space.append(z.cpu().numpy())\n",
    "            labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    return np.vstack(latent_space), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent_space: (11584, 2)\n",
      "Shape of labels: 181\n",
      "Unique labels: [-1  1  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "# Extract latent space from the validation dataset\n",
    "latent_space, labels = extract_latent_space(model, val_loader)\n",
    "\n",
    "\n",
    "# Check dimensions\n",
    "print(\"Shape of latent_space:\", latent_space.shape)\n",
    "print(\"Shape of labels:\", len(labels))\n",
    "print(\"Unique labels:\", np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = latent_space.reshape(181, 64, 2)\n",
    "latent_space = np.sum(latent_space, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    labels[i] = labels[i][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    labels[i] = np.full(64, labels[i][0])\n",
    "\n",
    "labels = np.concatenate(labels)\n",
    "labels = labels.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use t-SNE to reduce the 10D latent space into a 2D space\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "latent_tsne = tsne.fit_transform(latent_space)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid RGBA argument: 'tab:black'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m idx,label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(np\u001b[39m.\u001b[39munique(labels)):\n\u001b[0;32m---> 10\u001b[0m     plt\u001b[39m.\u001b[39mscatter(latent_space[labels\u001b[39m==\u001b[39mlabel, \u001b[39m0\u001b[39m], latent_space[labels\u001b[39m==\u001b[39mlabel, \u001b[39m1\u001b[39m], label\u001b[39m=\u001b[39mlabel_mapping[label],c\u001b[39m=\u001b[39mcmap(idx))\n\u001b[1;32m     11\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m     12\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mLatent Dimension 1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:707\u001b[0m, in \u001b[0;36mColormap.__call__\u001b[0;34m(self, X, alpha, bytes)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mRGBA values with a shape of ``X.shape + (4, )``.\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isinit:\n\u001b[0;32m--> 707\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init()\n\u001b[1;32m    709\u001b[0m \u001b[39m# Take the bad mask from a masked array, or in all other cases defer\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# np.isnan() to after we have converted to an array.\u001b[39;00m\n\u001b[1;32m    711\u001b[0m mask_bad \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mmask \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mis_masked(X) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:1166\u001b[0m, in \u001b[0;36mListedColormap._init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_init\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lut \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m), \u001b[39mfloat\u001b[39m)\n\u001b[0;32m-> 1166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lut[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m to_rgba_array(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolors)\n\u001b[1;32m   1167\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isinit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_extremes()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:485\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    483\u001b[0m         rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(c)\n\u001b[1;32m    484\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m         rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:485\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    483\u001b[0m         rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(c)\n\u001b[1;32m    484\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 485\u001b[0m         rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:299\u001b[0m, in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    297\u001b[0m     rgba \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[1;32m    300\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m         _colors_full_map\u001b[39m.\u001b[39mcache[c, alpha] \u001b[39m=\u001b[39m rgba\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:374\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid string grayscale value \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValue must be within 0-1 range\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    373\u001b[0m         \u001b[39mreturn\u001b[39;00m c, c, c, alpha \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m1.\u001b[39m\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    375\u001b[0m \u001b[39m# turn 2-D array into 1-D array\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(c, np\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 'tab:black'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot latent space\n",
    "colors_list = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \n",
    "               'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan',] * 2\n",
    "\n",
    "cmap = ListedColormap(colors_list)\n",
    "\n",
    "#plt.style.use('seaborn-v0_8-muted')\n",
    "plt.figure(figsize=(10, 7))\n",
    "for idx,label in enumerate(np.unique(labels)):\n",
    "    plt.scatter(latent_space[labels==label, 0], latent_space[labels==label, 1], label=label_mapping[label],c=cmap(idx))\n",
    "plt.legend()\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 29344\n",
      "Length of labels array: 917\n"
     ]
    }
   ],
   "source": [
    "num_train_points = len(train_loader.dataset) * train_loader.batch_size\n",
    "num_val_points = len(val_loader.dataset) * val_loader.batch_size\n",
    "total_num_points = num_train_points + num_val_points\n",
    "\n",
    "print(f\"Number of data points: {total_num_points}\")\n",
    "print(f\"Length of labels array: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 153819 elements, which is inconsistent with 'x' and 'y' with size 117376.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4439\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4438\u001b[0m \u001b[39mtry\u001b[39;00m:  \u001b[39m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[0;32m-> 4439\u001b[0m     colors \u001b[39m=\u001b[39m mcolors\u001b[39m.\u001b[39;49mto_rgba_array(c)\n\u001b[1;32m   4440\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:487\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:487\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:299\u001b[0m, in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[1;32m    300\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/colors.py:381\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39miterable(c):\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(c) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 8.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Plot the clustering results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(z_2d[:, \u001b[39m0\u001b[39;49m], z_2d[:, \u001b[39m1\u001b[39;49m], c\u001b[39m=\u001b[39;49mlabels, cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mviridis\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mcolorbar()\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/pyplot.py:2862\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[1;32m   2858\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m   2859\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2860\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2861\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2862\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mscatter(\n\u001b[1;32m   2863\u001b[0m         x, y, s\u001b[39m=\u001b[39;49ms, c\u001b[39m=\u001b[39;49mc, marker\u001b[39m=\u001b[39;49mmarker, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   2864\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin, vmax\u001b[39m=\u001b[39;49mvmax, alpha\u001b[39m=\u001b[39;49malpha, linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[1;32m   2865\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors, plotnonfinite\u001b[39m=\u001b[39;49mplotnonfinite,\n\u001b[1;32m   2866\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2867\u001b[0m     sci(__ret)\n\u001b[1;32m   2868\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4602\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4599\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4600\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   4601\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[0;32m-> 4602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[1;32m   4603\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[1;32m   4604\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[1;32m   4606\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4607\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4445\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4444\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_shape:\n\u001b[0;32m-> 4445\u001b[0m         \u001b[39mraise\u001b[39;00m invalid_shape_exception(c\u001b[39m.\u001b[39msize, xsize) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   4446\u001b[0m     \u001b[39m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[1;32m   4447\u001b[0m     \u001b[39m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[1;32m   4448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4449\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument must be a color, a sequence of colors, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4450\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mor a sequence of numbers, not \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 153819 elements, which is inconsistent with 'x' and 'y' with size 117376."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the clustering results\n",
    "plt.scatter(z_2d[:, 0], z_2d[:, 1], c=labels, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
